{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "9_FzH13EjseR",
    "outputId": "9d50107f-89ec-486d-e812-1a5e0e88fcbd"
   },
   "outputs": [],
   "source": [
    "# install dependencies:\n",
    "# (using +cu100 because colab is on CUDA 10.0)\n",
    "\n",
    "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
    "!pip install cython pyyaml==5.1\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "\n",
    "import torch, torchvision\n",
    "torch.__version__\n",
    "!gcc --version\n",
    "\n",
    "# Install Detectron2\n",
    "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
    "pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
    "!cp detectron2_repo/configs ./ -r\n",
    "# opencv is pre-installed on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart runtime in case you are installing detectron for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "try:\n",
    "    from google.colab.patches import cv2_imshow\n",
    "except:\n",
    "    os.system(f\"\"\"pip install google.colab\"\"\")\n",
    "    from google.colab.patches import cv2_imshow\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common .detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder structure to follow to directly use this notebook\n",
    "\n",
    "```\n",
    "EndoCV_Det\n",
    "│   class_list_bbox.txt  \n",
    "│\n",
    "└─── TRAIN\n",
    "│      └ images\n",
    "│      └ bbox\n",
    "└─── VAL\n",
    "│      └ images\n",
    "│      └ bbox\n",
    "└─── HOLDOUT  (Holdout set is optional)\n",
    "       └ images\n",
    "       └ bbox\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohbyys0ig2vs"
   },
   "outputs": [],
   "source": [
    "def get_bb(img_path, img_name):\n",
    "    \"\"\"\n",
    "        This function returns annotations in the format\n",
    "        xyxy_ABS: xmin, ymin, xmax, ymax - ABSOLUTE\n",
    "        \n",
    "        Function built taking into consideration the dataset\n",
    "        provided by EAD2020\n",
    "        \n",
    "        change the path to the bounding box folder(if not training on EAD)\n",
    "        and change the loading method(if using .mat) accordingly\n",
    "    \"\"\"\n",
    "    bb_path = img_path[:-7]+'bbox/'\n",
    "    img = plt.imread(img_path+img_name)\n",
    "    m, n, _ = img.shape\n",
    "    labels = np.loadtxt(bb_path+img_name[:-4]+'.txt').reshape(-1, 5)\n",
    "    classes = np.empty(len(labels), dtype=np.int32)\n",
    "    xyxy = np.empty((len(labels), 4), dtype=np.int32)\n",
    "    for i, label in enumerate(labels):\n",
    "        cls, x, y, w, h = label\n",
    "        x1 = (x-w/2.)\n",
    "        x2 = x1 + w\n",
    "        y1 = (y-h/2.)\n",
    "        y2 = y1 + h\n",
    "        x1 = np.clip(int(x1 * n), 0, n-1) ; x2 = np.clip(int(x2*n), 0, n-1)\n",
    "        y1 = np.clip(int(y1 * m), 0, m-1) ; y2 = np.clip(int(y2*m), 0, m-1)\n",
    "        classes[i] = int(cls)\n",
    "        xyxy[i] = [x1, y1, x2, y2]\n",
    "        \n",
    "    return xyxy, classes\n",
    "\n",
    "\n",
    "def _get_dicts(phase):\n",
    "    if phase == 'train':\n",
    "        path = 'EndoCV_Det/TRAIN/images/'\n",
    "    elif phase == 'val':\n",
    "        path = 'EndoCV_Det/VAL/images/'\n",
    "    else:\n",
    "        raise(Exception('Provide either \"Train\" or \"Val\"'))\n",
    "    \n",
    "    def get_dicts():\n",
    "        dataset_dicts = []\n",
    "        img_list = os.listdir(path)\n",
    "        for idx, i in enumerate(img_list):\n",
    "            record = {}\n",
    "            img = plt.imread(path+i)\n",
    "            height, width, _ = img.shape        \n",
    "            record[\"file_name\"] = path+i\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "            proposal_bb, proposal_logits = get_bb(path, i)\n",
    "            objs=[]\n",
    "            for j in range(len(proposal_bb)):\n",
    "                obj = {\n",
    "                    \"bbox\": [proposal_bb[j][0], proposal_bb[j][1], proposal_bb[j][2], proposal_bb[j][3]],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"category_id\": proposal_logits[j],\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "                objs.append(obj)\n",
    "            record[\"annotations\"] = objs\n",
    "            record[\"thing_classes\"] = [\"specularity\",\"saturation\",\n",
    "                                          \"artifact\", \"blur\", \"contrast\", \"bubbles\",\n",
    "                                          \"instrument\", \"blood\"]\n",
    "            dataset_dicts.append(record)\n",
    "        return dataset_dicts\n",
    "    return get_dicts\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"endo1_\" + d, _get_dicts(d))\n",
    "    MetadataCatalog.get(\"endo1_\" + d).set(thing_classes=[\"specularity\",\"saturation\",\n",
    "                                      \"artifact\", \"blur\", \"contrast\", \"bubbles\",\n",
    "                                      \"instrument\", \"blood\"])\n",
    "endo_metadata = MetadataCatalog.get(\"endo1_train\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ljbWTX0Wi8E"
   },
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "UkNbUzUOLYf0",
    "outputId": "6f7518a7-daf1-42d1-cef6-4951e3a8bcd1"
   },
   "outputs": [],
   "source": [
    "dataset_dicts = _get_dicts('train')()\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=endo_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "### To see available models:\n",
    "Look under the folder `detectron2_repo/configs/COCO-Detection/` for config files available for detection models.\n",
    "\n",
    "\n",
    "For eg:\n",
    "    \"detectron2_repo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7unkuuiqLdqd",
    "outputId": "80cad53a-b2dc-4f93-9602-60e08bb6b633"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "config_file = \"COCO-Detection/faster_rcnn_R_101_C4_3x.yaml\"\n",
    "# config_file = \"COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml\"\n",
    "# config_file = \"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"\n",
    "# config_file = \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
    "\n",
    "cfg.merge_from_file(f\"configs/{config_file}\")\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_file)\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"endo1_train\",)\n",
    "cfg.DATASETS.TEST = (\"endo1_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Automatically switch to a new tensorboard directory every time this cell is executed\n",
    "i = 1\n",
    "name_desc = config_file  # Extended Name for the Run\n",
    "notes= config_file + \": Serious run\"  # Notes, if any\n",
    "\n",
    "while os.path.exists(os.path.join(cfg.OUTPUT_DIR, f'run{i}')):\n",
    "    i += 1\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "cfg.OUTPUT_DIR = os.path.join('./output/', f'run{i}')\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "# WandB\n",
    "config = dict(cfg)\n",
    "del config['MODEL']\n",
    "wandb.init(\n",
    "    name=f\"Run {i}{': ' if name_desc else ''}{name_desc}\",  # Name to display in wandb\n",
    "    notes=notes,  # Notes, if any\n",
    "    project='endocv-det',  # Project name as on WandB website\n",
    "    sync_tensorboard=True,\n",
    "    config=config  # Save hyperparameters\n",
    ")\n",
    "\n",
    "# Launch Tensorboard\n",
    "%load_ext tensorboard\n",
    "!pkill tensorboard\n",
    "%tensorboard --logdir=output/run{i} --port=6007\n",
    "\n",
    "# Commence Training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0e4vdDIOXyxF"
   },
   "source": [
    "## Inference & evaluation using the trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.confidence_threshold = 0.4\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = cfg.confidence_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "U5LhISJqWXgM",
    "outputId": "69a6ee76-b1e5-48aa-c2ee-ec5313b8adbd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "cfg.DATASETS.TEST = (\"endo1_val\", )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "for t in ['train', 'val']:\n",
    "    dataset_dicts = _get_dicts(t)()\n",
    "\n",
    "    print(\"\\n\"*2 + t.upper() + \"\\n\"*2)\n",
    "    for d in random.sample(dataset_dicts, 10):\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1],\n",
    "                       metadata=MetadataCatalog.get(f\"endo1_{t}\"), \n",
    "                       scale=0.8, \n",
    "        )\n",
    "        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        cv2_imshow(v.get_image()[:, :, ::-1])\n",
    "        os.makedirs(os.path.join(cfg.OUTPUT_DIR, f'{t}_preds/'), exist_ok=True)\n",
    "        \n",
    "        # WandB\n",
    "        wandb.log({f\"{t}: {d['file_name']}\": [wandb.Image(v.get_image(), caption=f\"Threshold: {cfg.confidence_threshold}\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict \n",
    "Predict on the test directory and create submission folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dicts_test(folder='EndoCV_Det/TEST/images/'):\n",
    "    path = folder\n",
    "    def get_dicts_test():\n",
    "        dataset_dicts = []\n",
    "        img_list = os.listdir(path)\n",
    "        for idx, i in enumerate(img_list):\n",
    "            record = {}\n",
    "            try:\n",
    "                img = plt.imread(os.path.join(path, i))\n",
    "                height, width, _ = img.shape\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            record[\"file_name\"] = os.path.join(path, i)\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "            record[\"thing_classes\"] = [\"specularity\",\"saturation\",\n",
    "                                          \"artifact\", \"blur\", \"contrast\", \"bubbles\",\n",
    "                                          \"instrument\", \"blood\"]\n",
    "            dataset_dicts.append(record)\n",
    "        return dataset_dicts\n",
    "    return get_dicts_test\n",
    "\n",
    "\n",
    "def create_txt(a, name, folder, save_folder):\n",
    "    \"\"\"\n",
    "       This function will create a .txt file of the name given\n",
    "       or append to the existing one.\n",
    "    \"\"\"\n",
    "\n",
    "    save_path = f\"{save_folder}/{folder.lower() if folder != 'Detection_sequence' else 'sequence'}_bbox\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    path=f\"{save_path}/{name}\"\n",
    "    \n",
    "    pred_boxes = a['pred_boxes'].tensor.detach().cpu().numpy()\n",
    "    scores = a['scores'].detach().cpu().numpy()\n",
    "    pred_classes = a['pred_classes'].detach().cpu().numpy()\n",
    "    names = {0:'specularity', 1 : 'saturation', 2 : 'artifact', 3: 'blur',\n",
    "         4 :'contrast', 5 : 'bubbles', 6 : 'instrument', 7 : 'blood'}\n",
    "    \n",
    "    f = open(path, 'a+')\n",
    "    for i in range(len(pred_boxes)):\n",
    "        x1, y1, x2, y2 = pred_boxes[i]\n",
    "        label = pred_classes[i]\n",
    "        confidence = scores[i]\n",
    "        content = names[label]+\" \"+str(confidence)+\" \"+str(int((x1)))+\" \"+str(int(y1))+\" \"+str(int(x2))+\" \"+str(int(y2))+\"\\n\"\n",
    "        f.write(content)\n",
    "    print(f'\\rSaved {path}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg.confidence_threshold = 0.4\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "visualize_preds = True\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = cfg.confidence_threshold \n",
    "\n",
    "j = 1\n",
    "while os.path.exists(f\"EndoCV2020_testSubmission{j}\"):\n",
    "    j += 1\n",
    "os.makedirs(f\"EndoCV2020_testSubmission{j}\")\n",
    "\n",
    "for folder in ['Detection', 'Detection_sequence', 'Generalization']:\n",
    "    print(f'\\n\\n{folder}\\n\\n')\n",
    "    folder = os.path.join('EndoCV_Det/TEST/', folder)\n",
    "    dataset_dicts = _get_dicts_test(folder=folder)()\n",
    "    outputs = []\n",
    "    files = []\n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    \n",
    "    print(f'Predicting on {folder}...', end='')\n",
    "    for d in dataset_dicts:\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        output = predictor(im)\n",
    "        outputs.append(output)\n",
    "        files.append(f\"{os.path.basename(d['file_name'])[:-4]}.txt\")\n",
    "    print('Done!')\n",
    "    \n",
    "    if visualize_preds:\n",
    "        print('Sample Predictions')\n",
    "        for i in random.sample(range(len(outputs)), 3):\n",
    "            output, file = outputs[i], files[i]\n",
    "            im = cv2.imread(os.path.join(folder, file[:-4] + '.jpg'))\n",
    "            v = Visualizer(im[:, :, ::-1],\n",
    "                       metadata=MetadataCatalog.get(f\"endo1_val\"), \n",
    "                       scale=0.8, \n",
    "            )\n",
    "            v = v.draw_instance_predictions(output[\"instances\"].to(\"cpu\"))\n",
    "            cv2_imshow(v.get_image()[:, :, ::-1])\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(len(outputs))):\n",
    "        output = outputs[i]['instances'].get_fields()\n",
    "        create_txt(output, files[i], os.path.basename(folder), f\"EndoCV2020_testSubmission{j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model's performance on any folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dicts_test(folder='EndoCV_Det/HOLDOUT/images/'):\n",
    "    path = folder\n",
    "    def get_dicts_test():\n",
    "        dataset_dicts = []\n",
    "        img_list = os.listdir(path)\n",
    "#         print(img_list)\n",
    "        for idx, i in enumerate(img_list):\n",
    "            record = {}\n",
    "            try:\n",
    "                img = plt.imread(path+i)\n",
    "                height, width, _ = img.shape\n",
    "            except:\n",
    "                print(i)\n",
    "                continue\n",
    "            record[\"file_name\"] = path+i\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "            record[\"thing_classes\"] = [\"specularity\",\"saturation\",\n",
    "                                          \"artifact\", \"blur\", \"contrast\", \"bubbles\",\n",
    "                                          \"instrument\", \"blood\"]\n",
    "            dataset_dicts.append(record)\n",
    "        return dataset_dicts\n",
    "    return get_dicts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = 'EndoCV_Det/TEST/Detection/'\n",
    "cfg.confidence_threshold = 0.5\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "visualize_preds = True\n",
    "n_samples = 10\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = cfg.confidence_threshold\n",
    "cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = cfg.confidence_threshold \n",
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "cfg.DATASETS.TEST = (\"endo1_val\", )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "dataset_dicts = _get_dicts_test(folder=folder)()\n",
    "\n",
    "for d in random.sample(dataset_dicts, n_samples):\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(f\"endo1_val\"), \n",
    "                   scale=0.8, \n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Detectron2 Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
